{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import math\n",
    "from random import random, randint, shuffle\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression as PythonLogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as PythonKNN\n",
    "from sklearn.svm import SVC as PythonSVM\n",
    "from sklearn.tree import DecisionTreeClassifier as PythonDecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as PythonRandomForest\n",
    "from sklearn import metrics\n",
    "from collections import namedtuple\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegr:\n",
    "    def __init__(self, epochs=100):\n",
    "        self._pred_substruc = None\n",
    "        self.__epochs = epochs\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        class Similarity_Function:\n",
    "            def __init__(self, x, y):\n",
    "                one = np.fromiter((1 for _ in range(x.shape[0])), dtype=float)\n",
    "                self._x = np.append(one[:,np.newaxis], x, axis=1)\n",
    "                self._y = y\n",
    "\n",
    "            def __call__(self, b):\n",
    "                polynome = np.sum(self._x * b, axis=1)\n",
    "                prob = 1 / (1 + np.exp(-polynome))\n",
    "                return -(np.sum(self._y * np.log(prob) + (1 - self._y) * np.log(1 - prob)))\n",
    "\n",
    "        class SF_Jacobian(Similarity_Function):\n",
    "            def __call__(self, b):\n",
    "                polynome = np.sum(self._x * b, axis=1)\n",
    "                mul = np.sum(self._y - 1 / (1 + np.exp(-polynome)))\n",
    "                print(\"jac mul:\", mul)\n",
    "                return -b * mul\n",
    "\n",
    "        class Pred_substruc:\n",
    "            def __init__(self, b):\n",
    "                self.__b = b\n",
    "\n",
    "            def __call__(self, x):\n",
    "                one = np.array([1] * x.shape[0])\n",
    "                x_axis = np.append(one[:,np.newaxis], x, axis=1)\n",
    "                polynome = np.sum(x_axis * self.__b, axis=1)\n",
    "                return 1 / (1 + np.exp(-polynome))\n",
    "\n",
    "        start = (np.random.random(features.shape[1] + 1) - 0.5)\n",
    "\n",
    "        self.__coefs = minimize(\n",
    "            Similarity_Function(features, targets), start, method='CG', \n",
    "#             jac=SF_Jacobian(features, targets),\n",
    "            options={'maxiter': self.__epochs}\n",
    "        ).x\n",
    "\n",
    "        self._pred_substruc = Pred_substruc(self.__coefs)\n",
    "        self.__threshold = 0.5\n",
    "\n",
    "    def predict(self, features):\n",
    "        if not self._pred_substruc is None and self.__coefs.size == features.shape[1] + 1:\n",
    "            return (self._pred_substruc(features) > self.__threshold) * 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__ (self, k):\n",
    "        self.k = k\n",
    "        self.classes = 2\n",
    "        self.features = None\n",
    "        self.targets = None\n",
    "        \n",
    "    def dist(self, a, b):\n",
    "        root_pow = len(a)\n",
    "        dist = 0\n",
    "        for elem in a:\n",
    "            if (elem < 10): elem *= 100\n",
    "            dist += elem * elem\n",
    "            \n",
    "        dist = pow(dist, 1/root_pow)\n",
    "        return dist\n",
    "    \n",
    "    def fit (self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    \n",
    "    def predict(self, test_data):\n",
    "        \n",
    "        testLabels = []\n",
    "        \n",
    "        for testPoint in test_data:\n",
    "            #Claculate distances between test point and all of the train points\n",
    "            testDist = [ [self.dist(testPoint, self.features[i]), self.targets[i]] for i in range(len(self.features))]\n",
    "#             print(testDist)\n",
    "            #How many points of each class among nearest K\n",
    "            stat = [0 for i in range(self.classes)]\n",
    "            for d in sorted(testDist)[0:self.k]:\n",
    "                stat[d[1]] += 1\n",
    "            #Assign a class with the most number of occurences among K nearest neighbours\n",
    "            testLabels.append( sorted(zip(stat, range(self.classes)), reverse=True)[0][1] )\n",
    "        return testLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_SVM():\n",
    "    def __init__(self, epochs=5, a=0.5):\n",
    "        self.__epochs = epochs\n",
    "        self.__a = a\n",
    "        self.__predicator = None\n",
    "        \n",
    "    def fit(self, features, targets):\n",
    "        class LossFunc:\n",
    "            def __init__(self, x, y, a):\n",
    "                fi = np.array([1] * x.shape[0])\n",
    "                self._x = np.append(fi[:,np.newaxis], x, axis=1)\n",
    "                self._y = y\n",
    "                self._a = a\n",
    "                self._i = 0\n",
    "            \n",
    "            def _iterate(self):\n",
    "                self._i += 1\n",
    "                if self._i == len(self._x):\n",
    "                    self._i = 0\n",
    "            \n",
    "            def __call__(self, w):\n",
    "                res = max(0.0, 1.0 - self._y[self._i] * np.sum(w * self._x[self._i])) + self._a * np.sum(w * w) / 2\n",
    "                self._iterate()\n",
    "                return res\n",
    "            \n",
    "        class Jac(LossFunc):\n",
    "            def __call__(self, w):\n",
    "                if self._y[self._i] * np.sum(w * self._x[self._i]) < 1:\n",
    "                    res = self._a * w - self._y[self._i] * self._x[self._i]\n",
    "                else:\n",
    "                    res = self._a * w\n",
    "                self._iterate()\n",
    "                return res\n",
    "            \n",
    "        class Predicator:\n",
    "            def __init__(self, w):\n",
    "                self.__w = w\n",
    "\n",
    "            def __call__(self, x):\n",
    "                fi = np.array([1] * x.shape[0])\n",
    "                xa = np.append(fi[:,np.newaxis], x, axis=1)\n",
    "                return np.sum(self.__w * xa, axis=1)\n",
    "            \n",
    "        start = np.random.random(features.shape[1] + 1) - 0.5\n",
    "\n",
    "        m_func = LossFunc(features, targets, self.__a)\n",
    "        m_jac = Jac(features, targets, self.__a)\n",
    "\n",
    "        for i in range(self.__epochs):\n",
    "            for j in range(features.shape[0]):\n",
    "                self.__coefs = minimize(\n",
    "                    m_func, start, method='CG', \n",
    "                    jac=m_jac,\n",
    "                    options={'maxiter': 1}\n",
    "                ).x\n",
    "\n",
    "        self.__predicator = Predicator(self.__coefs)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        if not self.__predicator is None and self.__coefs.size == features.shape[1] + 1:\n",
    "            return (self.__predicator(features) > 0) * 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeLeaf:\n",
    "    def __init__(self, decision):\n",
    "        self.__decision = decision\n",
    "\n",
    "    def predict(self, point):\n",
    "        return self.__decision\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature, separator, left, right):\n",
    "        self.__feature = feature\n",
    "        self.__separator = separator\n",
    "        self.__left = left\n",
    "        self.__right = right\n",
    "\n",
    "    def predict(self, point):\n",
    "        if point[self.__feature] <= self.__separator:\n",
    "            return self.__left.predict(point)\n",
    "        else:\n",
    "            return self.__right.predict(point)\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, depth=None):\n",
    "        self.__root = None\n",
    "        self.__depth = depth\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        self.__root = self.__construct(features, targets)\n",
    "\n",
    "    def predict(self, points):\n",
    "        if self.__root is not None:\n",
    "            ans = []\n",
    "            for point in points:\n",
    "                ans.append(self.__root.predict(point))\n",
    "            return np.array(ans)\n",
    "\n",
    "    def __construct(self, features, targets, depth=0):\n",
    "        unique_targets = np.unique(targets)\n",
    "        if unique_targets.size == 1:\n",
    "            return DecisionTreeLeaf(unique_targets[0])\n",
    "\n",
    "        if not self.__depth is None and self.__depth == depth:\n",
    "            return DecisionTreeLeaf(self.__get_freq_target(targets))\n",
    "\n",
    "        max_gain = None\n",
    "        for i in range(features.shape[1]):\n",
    "            curr_gain, curr_sep = self.__information_gain(features[:,i], targets)\n",
    "            if max_gain is None or curr_gain > max_gain:\n",
    "                max_ind = i\n",
    "                max_sep = curr_sep\n",
    "                max_gain = curr_gain\n",
    "\n",
    "        left = ([], [])\n",
    "        right = ([], [])\n",
    "        for i in range(features.shape[0]):\n",
    "            if features[i, max_ind] <= max_sep:\n",
    "                left[0].append(features[i])\n",
    "                left[1].append(targets[i])\n",
    "            else:\n",
    "                right[0].append(features[i])\n",
    "                right[1].append(targets[i])\n",
    "\n",
    "        if len(left[0]) == 0 or len(right[0]) == 0:\n",
    "            return DecisionTreeLeaf(self.__get_freq_target(targets))\n",
    "\n",
    "        return DecisionTreeNode(\n",
    "            feature=max_ind,\n",
    "            separator=max_sep,\n",
    "            left=self.__construct(np.array(left[0]), np.array(left[1]), depth + 1),\n",
    "            right=self.__construct(np.array(right[0]), np.array(right[1]), depth + 1)\n",
    "        \n",
    "        )\n",
    "\n",
    "    def __information_gain(self, features, targets):\n",
    "        targets_counts = {}\n",
    "        for target in targets:\n",
    "            if target not in targets_counts:\n",
    "                targets_counts[target] = 0\n",
    "            targets_counts[target] += 1\n",
    "\n",
    "        sorted_targets_inds = np.argsort(features)\n",
    "        values = np.sort(features)\n",
    "\n",
    "        optimal_separator = None\n",
    "        curr_targets_counts = {}\n",
    "        for target in targets_counts:\n",
    "            curr_targets_counts[target] = 0\n",
    "\n",
    "        for i in range(len(targets) - 1):\n",
    "            curr_targets_counts[targets[sorted_targets_inds[i]]] += 1\n",
    "\n",
    "            curr_information_ammount = 0\n",
    "            for target in targets_counts:\n",
    "                p1 = curr_targets_counts[target] / (i + 1)\n",
    "                p2 = (targets_counts[target] - curr_targets_counts[target]) / (len(targets) - (i + 1))\n",
    "\n",
    "                if p1 > 0:\n",
    "                    curr_information_ammount -= p1 * math.log(p1, 2)\n",
    "                if p2 > 0:\n",
    "                    curr_information_ammount -= p2 * math.log(p2, 2)\n",
    "\n",
    "            if optimal_separator is None or curr_information_ammount < optimal_information_ammount:\n",
    "                optimal_separator = values[i]\n",
    "                optimal_information_ammount = curr_information_ammount\n",
    "\n",
    "        base_information_ammount = 0\n",
    "        for target_count in targets_counts.values():\n",
    "            p = target_count / len(features)\n",
    "            base_information_ammount -= p * math.log(p, 2)\n",
    "\n",
    "        return (base_information_ammount - optimal_information_ammount, optimal_separator)\n",
    "\n",
    "    def __get_freq_target(self, targets):\n",
    "        targets_count = {}\n",
    "\n",
    "        for target in targets:\n",
    "            if not target in targets_count:\n",
    "                targets_count[target] = 0\n",
    "            targets_count[target] += 1\n",
    "\n",
    "        best_target = None\n",
    "        for curr_target in targets_count:\n",
    "            if best_target is None or targets_count[best_target] < targets_count[curr_target]:\n",
    "                best_target = curr_target\n",
    "\n",
    "        return best_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, trees_count=None, depth=None, effective_factors=None):\n",
    "        self.__trees_count = trees_count\n",
    "        self.__depth = depth\n",
    "        self.__effective_factors = effective_factors\n",
    "        self.__trees = None\n",
    "\n",
    "    def fit(self, features, targets):\n",
    "        if self.__effective_factors is None:\n",
    "            self.__effective_factors = math.floor(math.sqrt(features.shape[1]))\n",
    "        if self.__effective_factors > features.shape[1]:\n",
    "            self.__effective_factors = features.shape[1]\n",
    "\n",
    "        if self.__trees_count is None:\n",
    "            self.__trees_count = math.ceil(math.sqrt(features.shape[1]))\n",
    "\n",
    "        self.__trees = []\n",
    "\n",
    "        for i in range(self.__trees_count):\n",
    "            points_inds = [randint(0, features.shape[0] - 1) for i in range(features.shape[0])]\n",
    "            tmp = [i for i in range(features.shape[1])]\n",
    "            shuffle(tmp)\n",
    "            targets_inds = sorted(tmp[:self.__effective_factors])\n",
    "\n",
    "            curr_points = []\n",
    "            curr_targets = []\n",
    "            for ind in points_inds:\n",
    "                curr_points.append(features[ind])\n",
    "                curr_targets.append(targets[ind])\n",
    "\n",
    "            curr_points = np.array(curr_points)\n",
    "            curr_targets = np.array(curr_targets)\n",
    "\n",
    "            trunc_factors = curr_points[:, targets_inds[0], np.newaxis]\n",
    "            for ind in targets_inds[1:]:\n",
    "                np.append(trunc_factors, curr_points[:, ind, np.newaxis], axis=1)\n",
    "\n",
    "            curr_tree = DecisionTree(self.__depth)\n",
    "            curr_tree.fit(trunc_factors, curr_targets)\n",
    "            self.__trees.append(curr_tree)\n",
    "\n",
    "    def predict(self, points):\n",
    "        ans = []\n",
    "        for point in points:\n",
    "            votes = {}\n",
    "            for tree in self.__trees:\n",
    "                pred = tree.predict([point])[0]\n",
    "                if pred not in votes:\n",
    "                    votes[pred] = 0\n",
    "                votes[pred] += 1\n",
    "\n",
    "            predicted_class = None\n",
    "            for class_id, votes_count in votes.items():\n",
    "                if predicted_class is None or votes[predicted_class] < votes_count:\n",
    "                    predicted_class = class_id\n",
    "\n",
    "            ans.append(predicted_class)\n",
    "        return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(\"C:/Users/cerma/Desktop/MAI/3c/AI/lab1/classification_data/star_class_ready.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.random.rand(len(data))\n",
    "sampling_rate = 0.8\n",
    "training_mask = probs < sampling_rate\n",
    "test_mask = probs >= sampling_rate\n",
    "\n",
    "learn_data = data[training_mask]\n",
    "learn_features = learn_data.drop(\"Star type\", axis='columns').to_numpy()\n",
    "learn_targets = learn_data[\"Star type\"].to_numpy()\n",
    "for i in range(0, len(learn_targets)):\n",
    "    if learn_targets[i] > 2:\n",
    "        learn_targets[i] = 1\n",
    "    else :\n",
    "        learn_targets[i] = 0\n",
    "\n",
    "test_data = data[test_mask]\n",
    "test_features = test_data.drop(\"Star type\", axis='columns').to_numpy()\n",
    "test_targets = test_data[\"Star type\"].to_numpy()\n",
    "for i in range(0, len(test_targets)):\n",
    "    if test_targets[i] > 2:\n",
    "        test_targets[i] = 1\n",
    "    else :\n",
    "        test_targets[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_w_metrics(model, learn_features, learn_targets, test_features, test_targets, name):\n",
    "    model.fit(learn_features, learn_targets)\n",
    "    res = model.predict(test_features)\n",
    "    print(\"{} metrics:\".format(name))\n",
    "    print(\"accuracy:\", metrics.accuracy_score(test_targets, res))\n",
    "    print(\"precision:\", metrics.precision_score(test_targets, res))\n",
    "    print(\"f1 score:\", metrics.f1_score(test_targets, res))\n",
    "    print(\"recall:\", metrics.recall_score(test_targets, res))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My logistic regression metrics:\n",
      "accuracy: 0.8723404255319149\n",
      "precision: 1.0\n",
      "f1 score: 0.8571428571428571\n",
      "recall: 0.75\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cerma\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\cerma\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\cerma\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in multiply\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\cerma\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(LogRegr(), learn_features, learn_targets, test_features, test_targets, \"My logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python logistic regression metrics:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "f1 score: 1.0\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(PythonLogisticRegression(max_iter=500), learn_features, learn_targets, test_features, test_targets, \"Python logistic regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My KNN metrics:\n",
      "accuracy: 0.4878048780487805\n",
      "precision: 0.0\n",
      "f1 score: 0.0\n",
      "recall: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn_sampling_rate = 0.8\n",
    "\n",
    "knn_learn_probs = np.random.rand(len(learn_features))\n",
    "taken_mask = knn_learn_probs < knn_sampling_rate\n",
    "knn_learn_features = learn_features[taken_mask]\n",
    "knn_learn_targets = learn_targets[taken_mask]\n",
    "# print(knn_learn_targets)\n",
    "\n",
    "knn_test_probs = np.random.rand(len(test_features))\n",
    "taken_mask = knn_test_probs < knn_sampling_rate\n",
    "knn_test_features = test_features[taken_mask]\n",
    "knn_test_targets = test_targets[taken_mask]\n",
    "# print(knn_test_targets)\n",
    "\n",
    "learn_w_metrics(KNN(50), knn_learn_features, knn_learn_targets, knn_test_features, knn_test_targets, \"My KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python KNN metrics:\n",
      "accuracy: 0.9148936170212766\n",
      "precision: 1.0\n",
      "f1 score: 0.9090909090909091\n",
      "recall: 0.8333333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(PythonKNN(), learn_features, learn_targets, test_features, test_targets, \"Python KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My SVM metrics:\n",
      "accuracy: 0.3191489361702128\n",
      "precision: 0.39473684210526316\n",
      "f1 score: 0.48387096774193544\n",
      "recall: 0.625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(my_SVM(1), learn_features, learn_targets, test_features, test_targets, \"My SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python SVM metrics:\n",
      "accuracy: 0.8723404255319149\n",
      "precision: 1.0\n",
      "f1 score: 0.8571428571428571\n",
      "recall: 0.75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(PythonSVM(max_iter=1000), learn_features, learn_targets, test_features, test_targets, \"Python SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My decision tree metrics:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "f1 score: 1.0\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(DecisionTree(), learn_features, learn_targets, test_features, test_targets, \"My decision tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python decision tree metrics:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "f1 score: 1.0\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(PythonDecisionTree(), learn_features, learn_targets, test_features, test_targets, \"Python decision tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My random forest metrics:\n",
      "accuracy: 0.7021276595744681\n",
      "precision: 0.631578947368421\n",
      "f1 score: 0.7741935483870968\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(RandomForest(depth=4), learn_features, learn_targets, test_features, test_targets, \"My random forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python random forest metrics:\n",
      "accuracy: 1.0\n",
      "precision: 1.0\n",
      "f1 score: 1.0\n",
      "recall: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn_w_metrics(PythonRandomForest(), learn_features, learn_targets, test_features, test_targets, \"Python random forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
